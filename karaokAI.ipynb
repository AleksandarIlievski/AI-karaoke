{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jvv9-YPh7peb"
      },
      "source": [
        "# Download YouTube Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYL7qtzLC77u"
      },
      "outputs": [],
      "source": [
        "!pip install pytube pydub youtube-dl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPg1ZJXI_V-2"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "import os\n",
        "import re\n",
        "import torch\n",
        "import torchaudio\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from io import BytesIO\n",
        "\n",
        "from pydub import AudioSegment\n",
        "from pytube import YouTube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMG11VA8CWKF"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvJUpvVsYK7M"
      },
      "outputs": [],
      "source": [
        "bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H\n",
        "labels = bundle.get_labels()\n",
        "model = bundle.get_model().to(device)\n",
        "dictionary = {c: i for i, c in enumerate(labels)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuiWyfDDzI3h"
      },
      "outputs": [],
      "source": [
        "def get_wave(aud):\n",
        "  aud = aud.set_channels(1)\n",
        "  aud = aud.get_array_of_samples()\n",
        "  wave = torch.tensor(aud, dtype = torch.float)\n",
        "  wave = torch.reshape(wave, (1,wave.shape[0]))\n",
        "\n",
        "  return wave"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wav_sr_from_yt_video_id(video_id):\n",
        "    # Download the video using youtube-dl\n",
        "    os.system(\"youtube-dl --extract-audio --audio-format wav --audio-quality 0 -o '%(id)s.%(ext)s' https://youtu.be/{}\".format(video_id))\n",
        "\n",
        "    file_path = \"{}.wav\".format(video_id)\n",
        "\n",
        "    # Load the audio file using pydub\n",
        "    audio = AudioSegment.from_file(file_path, format=\"wav\")\n",
        "\n",
        "    waveform = get_wave(audio)\n",
        "    sr = audio.frame_rate\n",
        "\n",
        "    # Delete file\n",
        "    if os.path.isfile(file_path):\n",
        "        os.remove(file_path)\n",
        "    else:\n",
        "        print(\"{} does not exist.\".format(file_path))\n",
        "\n",
        "    # Resample\n",
        "    if sr != bundle.sample_rate:\n",
        "        waveform = torchaudio.functional.resample(waveform, sr, bundle.sample_rate)\n",
        "\n",
        "    return waveform, sr"
      ],
      "metadata": {
        "id": "M4OOyZbzKA7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6U_cJvYBkL4"
      },
      "outputs": [],
      "source": [
        "def clean_lyrics(lyrics):\n",
        "    lyrics = re.sub(r\"\\[.*?\\]\", \"\", lyrics, flags=re.MULTILINE)\n",
        "    lyrics = re.sub(r\"’\", \"'\", lyrics)\n",
        "    lyrics = re.sub(r\"[^a-zA-Z'’|-]|\\s\", \"|\", lyrics)\n",
        "    return lyrics.upper()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ru8UVKPBHGhv"
      },
      "outputs": [],
      "source": [
        "def calculate_emission(waveform):\n",
        "    torch.cuda.empty_cache()    \n",
        "    \n",
        "    length = waveform.shape[1]\n",
        "    chunks = []\n",
        "    amount_chunks = 10\n",
        "    chunks_length = length//amount_chunks\n",
        "    for i in range(amount_chunks):\n",
        "        with torch.inference_mode():\n",
        "            emissions, _ = model(waveform[:, i * chunks_length: min(length, (i + 1) * chunks_length)].to(device))\n",
        "            emissions = torch.log_softmax(emissions, dim=-1)\n",
        "            chunks.append(emissions)\n",
        "\n",
        "    return torch.cat(chunks, dim=1)[0].cpu().detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iv9CYtlFOSA"
      },
      "outputs": [],
      "source": [
        "def get_tokens(transcript):\n",
        "    return [dictionary[c] for c in transcript]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rznzh7LnnHri"
      },
      "outputs": [],
      "source": [
        "def get_trellis(emission, tokens, blank_id=0):\n",
        "    num_frame = emission.size(0)\n",
        "    num_tokens = len(tokens)\n",
        "\n",
        "    # Trellis has extra diemsions for both time axis and tokens.\n",
        "    # The extra dim for tokens represents <SoS> (start-of-sentence)\n",
        "    # The extra dim for time axis is for simplification of the code.\n",
        "    trellis = torch.empty((num_frame + 1, num_tokens + 1))\n",
        "    trellis[0, 0] = 0\n",
        "    trellis[1:, 0] = torch.cumsum(emission[:, 0], 0)\n",
        "    trellis[0, -num_tokens:] = -float(\"inf\")\n",
        "    trellis[-num_tokens:, 0] = float(\"inf\")\n",
        "\n",
        "    for t in range(num_frame):\n",
        "        trellis[t + 1, 1:] = torch.maximum(\n",
        "            # Score for staying at the same token\n",
        "            trellis[t, 1:] + emission[t, blank_id],\n",
        "            # Score for changing to the next token\n",
        "            trellis[t, :-1] + emission[t, tokens],\n",
        "        )\n",
        "    return trellis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Y3Mf-_qnHrk"
      },
      "source": [
        "## Find the most likely path (backtracking)\n",
        "\n",
        "Once the trellis is generated, we will traverse it following the\n",
        "elements with high probability.\n",
        "\n",
        "We will start from the last label index with the time step of highest\n",
        "probability, then, we traverse back in time, picking stay\n",
        "($c_j \\rightarrow c_j$) or transition\n",
        "($c_j \\rightarrow c_{j+1}$), based on the post-transition\n",
        "probability $k_{t, j} p(t+1, c_{j+1})$ or\n",
        "$k_{t, j+1} p(t+1, repeat)$.\n",
        "\n",
        "Transition is done once the label reaches the beginning.\n",
        "\n",
        "The trellis matrix is used for path-finding, but for the final\n",
        "probability of each segment, we take the frame-wise probability from\n",
        "emission matrix.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wMrjfxdnHrl"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Point:\n",
        "    token_index: int\n",
        "    time_index: int\n",
        "    score: float\n",
        "\n",
        "\n",
        "def backtrack(trellis, emission, tokens, blank_id=0):\n",
        "    # Note:\n",
        "    # j and t are indices for trellis, which has extra dimensions\n",
        "    # for time and tokens at the beginning.\n",
        "    # When referring to time frame index `T` in trellis,\n",
        "    # the corresponding index in emission is `T-1`.\n",
        "    # Similarly, when referring to token index `J` in trellis,\n",
        "    # the corresponding index in transcript is `J-1`.\n",
        "    j = trellis.size(1) - 1\n",
        "    t_start = torch.argmax(trellis[:, j]).item()\n",
        "\n",
        "    path = []\n",
        "    for t in range(t_start, 0, -1):\n",
        "        # 1. Figure out if the current position was stay or change\n",
        "        # Note (again):\n",
        "        # `emission[J-1]` is the emission at time frame `J` of trellis dimension.\n",
        "        # Score for token staying the same from time frame J-1 to T.\n",
        "        stayed = trellis[t - 1, j] + emission[t - 1, blank_id]\n",
        "        # Score for token changing from C-1 at T-1 to J at T.\n",
        "        changed = trellis[t - 1, j - 1] + emission[t - 1, tokens[j - 1]]\n",
        "\n",
        "        # 2. Store the path with frame-wise probability.\n",
        "        prob = emission[t - 1, tokens[j - 1] if changed > stayed else 0].exp().item()\n",
        "        # Return token index and time index in non-trellis coordinate.\n",
        "        path.append(Point(j - 1, t - 1, prob))\n",
        "\n",
        "        # 3. Update the token\n",
        "        if changed > stayed:\n",
        "            j -= 1\n",
        "            if j == 0:\n",
        "                break\n",
        "    else:\n",
        "        raise ValueError(\"Failed to align\")\n",
        "    return path[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTmzO9WBnHrn"
      },
      "outputs": [],
      "source": [
        "# Merge the labels\n",
        "@dataclass\n",
        "class Segment:\n",
        "    label: str\n",
        "    start: int\n",
        "    end: int\n",
        "    score: float\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"{self.label}\\t({self.score:4.2f}): [{self.start:5d}, {self.end:5d})\"\n",
        "\n",
        "    @property\n",
        "    def length(self):\n",
        "        return self.end - self.start\n",
        "\n",
        "\n",
        "def merge_repeats(path, transcript):\n",
        "    i1, i2 = 0, 0\n",
        "    segments = []\n",
        "    while i1 < len(path):\n",
        "        while i2 < len(path) and path[i1].token_index == path[i2].token_index:\n",
        "            i2 += 1\n",
        "        score = sum(path[k].score for k in range(i1, i2)) / (i2 - i1)\n",
        "        segments.append(\n",
        "            Segment(\n",
        "                transcript[path[i1].token_index],\n",
        "                path[i1].time_index,\n",
        "                path[i2 - 1].time_index + 1,\n",
        "                score,\n",
        "            )\n",
        "        )\n",
        "        i1 = i2\n",
        "    return segments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0azSem7nHro"
      },
      "source": [
        "### Visualization\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIVsRn3rnHrq"
      },
      "source": [
        "Looks good. Now let’s merge the words. The Wav2Vec2 model uses ``'|'``\n",
        "as the word boundary, so we merge the segments before each occurance of\n",
        "``'|'``.\n",
        "\n",
        "Then, finally, we segment the original audio into segmented audio and\n",
        "listen to them to see if the segmentation is correct.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wMoDWl9nHrs"
      },
      "outputs": [],
      "source": [
        "# Merge words\n",
        "def merge_words(segments, separator=\"|\"):\n",
        "    words = []\n",
        "    i1, i2 = 0, 0\n",
        "    while i1 < len(segments):\n",
        "        if i2 >= len(segments) or segments[i2].label == separator:\n",
        "            if i1 != i2:\n",
        "                segs = segments[i1:i2]\n",
        "                word = \"\".join([seg.label for seg in segs])\n",
        "                score = sum(seg.score * seg.length for seg in segs) / sum(seg.length for seg in segs)\n",
        "                words.append(Segment(word, segments[i1].start, segments[i2 - 1].end, score))\n",
        "            i1 = i2 + 1\n",
        "            i2 = i1\n",
        "        else:\n",
        "            i2 += 1\n",
        "    return words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Abt3GSLvnHrt"
      },
      "source": [
        "### Visualization\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9E9g0hvynHrx"
      },
      "outputs": [],
      "source": [
        "# A trick to embed the resulting audio to the generated file.\n",
        "# `IPython.display.Audio` has to be the last call in a cell,\n",
        "# and there should be only one call par cell.\n",
        "def display_segment(waveform, i):\n",
        "    ratio = waveform.size(1) / (trellis.size(0) - 1)\n",
        "    word = word_segments[i]\n",
        "    x0 = int(ratio * word.start)\n",
        "    x1 = int(ratio * word.end)\n",
        "    print(f\"{word.label} ({word.score:.2f}): {x0 / bundle.sample_rate:.3f} - {x1 / bundle.sample_rate:.3f} sec\")\n",
        "    segment = waveform[:, x0:x1]\n",
        "    return IPython.display.Audio(segment.numpy(), rate=bundle.sample_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99C0VJxLEzO0"
      },
      "outputs": [],
      "source": [
        "def execute(audio, transcript):\n",
        "    transcript = clean_lyrics(transcript)\n",
        "    emission = calculate_emission(audio)\n",
        "    tokens = get_tokens(transcript)\n",
        "    trellis = get_trellis(emission, tokens)\n",
        "    path = backtrack(trellis, emission, tokens)\n",
        "    segments = merge_repeats(path, transcript)\n",
        "    word_segments = merge_words(segments)\n",
        "    return emission, tokens, trellis, path, segments, word_segments"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example"
      ],
      "metadata": {
        "id": "jeKvp_zg7gkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "waveform, sr = get_wav_sr_from_yt_video_id(\"b1kbLwvqugk\")"
      ],
      "metadata": {
        "id": "YAV-d9Qh6v92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcript = \"\"\"\n",
        "I have this thing where I get older but just never wiser\n",
        "Midnights become my afternoons\n",
        "When my depression works the graveyard shift\n",
        "All of the people I've ghosted stand there in the room\n",
        "I should not be left to my own devices\n",
        "They come with prices and vices\n",
        "I end up in crisis (tale as old as time)\n",
        "I wake up screaming from dreaming\n",
        "One day I'll watch as you're leaving\n",
        "'Cause you got tired of my scheming\n",
        "(For the last time)\n",
        "It's me, hi, I'm the problem, it's me\n",
        "At tea time, everybody agrees\n",
        "I'll stare directly at the sun but never in the mirror\n",
        "It must be exhausting always rooting for the anti-hero\n",
        "Sometimes I feel like everybody is a sexy baby\n",
        "And I'm a monster on the hill\n",
        "Too big to hang out, slowly lurching toward your favorite city\n",
        "Pierced through the heart, but never killed\n",
        "Did you hear my covert narcissism I disguise as altruism\n",
        "Like some kind of congressman? (Tale as old as time)\n",
        "I wake up screaming from dreaming\n",
        "One day I'll watch as you're leaving\n",
        "And life will lose all its meaning\n",
        "(For the last time)\n",
        "It's me, hi, I'm the problem, it's me (I'm the problem, it's me)\n",
        "At tea time, everybody agrees\n",
        "I'll stare directly at the sun but never in the mirror\n",
        "It must be exhausting always rooting for the anti-hero\n",
        "I have this dream my daughter in-law kills me for the money\n",
        "She thinks I left them in the will\n",
        "The family gathers 'round and reads it and then someone screams out\n",
        "\"She's laughing up at us from hell\"\n",
        "It's me, hi, I'm the problem, it's me\n",
        "It's me, hi, I'm the problem, it's me\n",
        "It's me, hi, everybody agrees, everybody agrees\n",
        "It's me, hi (hi), I'm the problem, it's me (I'm the problem, it's me)\n",
        "At tea (tea) time (time), everybody agrees (everybody agrees)\n",
        "I'll stare directly at the sun but never in the mirror\n",
        "It must be exhausting always rooting for the anti-hero\"\"\""
      ],
      "metadata": {
        "id": "O2c8VyFz7K8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, _, trellis, _, _, word_segments = execute(waveform, transcript)\n",
        "word_segments"
      ],
      "metadata": {
        "id": "U2fPhbZp6h3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratio = waveform.size(1) / (trellis.size(0) - 1)\n",
        "\n",
        "start_at = 111\n",
        "end_at = start_at + 10\n",
        "\n",
        "x0 = int(ratio * word_segments[start_at].start)\n",
        "x1 = int(ratio * word_segments[end_at].end)\n",
        "segment = waveform[:, x0:x1]\n",
        "print(list(map(lambda x: x.label, word_segments[start_at:end_at + 1])))\n",
        "IPython.display.Audio(segment.numpy(), rate=bundle.sample_rate)"
      ],
      "metadata": {
        "id": "2kp5hWp_8sIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5r98YHbkoCD"
      },
      "source": [
        "# Website"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oczo-aQF1y5t"
      },
      "outputs": [],
      "source": [
        "!pip install jupyter-dash\n",
        "!pip install pytube\n",
        "!pip install dash-player"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tAGLtJW22L-"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lmqgvp2x21n-"
      },
      "outputs": [],
      "source": [
        "def extract_video_id(link):\n",
        "    regExp = re.compile(r'^.*(youtu.be\\/|v\\/|u\\/\\w\\/|embed\\/|watch\\?v=|&v=)([^#&?]*).*')\n",
        "    match_id = regExp.match(link)\n",
        "    if match_id:\n",
        "        video_id = match_id.group(2)\n",
        "        if len(video_id) == 11:\n",
        "            return video_id \n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysjNSJab2DeU"
      },
      "outputs": [],
      "source": [
        "from jupyter_dash import JupyterDash\n",
        "import dash_core_components as dcc\n",
        "import dash_html_components as html\n",
        "from dash.dependencies import Input, Output, State\n",
        "import dash_player"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCiI_-3o3Ag1"
      },
      "outputs": [],
      "source": [
        "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
        "app = JupyterDash(__name__, external_stylesheets=external_stylesheets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAPZVSK6FfyX"
      },
      "outputs": [],
      "source": [
        "app.layout = html.Div([\n",
        "    html.H1(\"AI Karaoke\"),\n",
        "    # Yt link\n",
        "    html.Div([\n",
        "        dcc.Input(id=\"input_yt\", placeholder=\"Input Youtube Link\", style={'width': '600px', 'margin-right': '5px'}),\n",
        "        html.Button('Submit', id='btn_submit', n_clicks=0),\n",
        "        html.Div(id=\"initial_message\", children=\"Enter a YouTube link and transcript and press submit to load video\", style={'display': 'block'}),\n",
        "        html.Div(id=\"invalid_link_div\", children=\"Invalid YouTube link\", style={'color': 'red', 'display': 'none'}),\n",
        "    ], style={'margin-bottom': '30px'}),\n",
        "     \n",
        "    # video and transcript\n",
        "    html.Div([\n",
        "        dash_player.DashPlayer(id=\"player\", url=\"\", controls=True, width=\"70%\", height=\"80%\", style={'display': 'inline-block', 'margin-right': '10px'}),\n",
        "        # TODO change input as you need\n",
        "        dcc.Interval(id='interval', interval=300, n_intervals=0),\n",
        "        dcc.Input(id=\"input_transcript\", placeholder=\"Input transcript\", style={'width': '29%', 'height': '80%', 'display': 'inline-block'})\n",
        "    ], style={'height': '100vh', 'width': '100%', 'display': 'flex'}),\n",
        "\n",
        "    # current video timestamp, only for debugging\n",
        "    html.Div(id=\"div_current_time\", style={\"margin\": \"10px 0px\"}),\n",
        "     \n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbTNd7q-INrw"
      },
      "outputs": [],
      "source": [
        "@app.callback(\n",
        "    [Output('player', 'url'),\n",
        "    Output('initial_message', 'style'),\n",
        "    Output('invalid_link_div', 'style')],\n",
        "    Input('btn_submit', 'n_clicks'),\n",
        "    State('input_yt', 'value')\n",
        ")\n",
        "def embed_video(n_clicks, link):\n",
        "    initial_message_style = {'display': 'block'}\n",
        "    invalid_style = {'color': 'red', 'display': 'none'}\n",
        "    url = \"\"\n",
        "    if n_clicks > 0:\n",
        "        # TODO maybe add loading bar\n",
        "        video_id = extract_video_id(link)\n",
        "        # download_yt_wav(link, './', video_id)\n",
        "        if video_id:\n",
        "            url = link\n",
        "        else:\n",
        "            initial_message_style = {'display': 'none'}\n",
        "            invalid_style = {'color': 'red', 'display': 'block'}\n",
        "    return url, initial_message_style, invalid_style\n",
        "\n",
        "# TODO complete this callback for displaying lyrics (with highlight)\n",
        "# TODO add State for current video timestamp (so if the user jumps inside the video, it shows the lyrics of the selected timestamp)\n",
        "# TODO find out why currentTime is only updating when skipping the video\n",
        "@app.callback(\n",
        "    Output('input_transcript', 'value'),\n",
        "    Input('btn_submit', 'n_clicks'),\n",
        "    Input('interval', 'n_intervals'),\n",
        "    State(\"player\", \"currentTime\"),\n",
        "    State('input_transcript', 'value'),\n",
        "    State('input_yt', 'value')\n",
        ")\n",
        "def compute_force_alignment(n_clicks, n_intervals, currentTime, transcript, link):\n",
        "    value = transcript\n",
        "    if n_clicks > 0:\n",
        "      #TODO compute alignment and current display of transcript\n",
        "      pass\n",
        "    return f\"Current Time: {currentTime}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTqlZniJ3IJx"
      },
      "outputs": [],
      "source": [
        "# click link to open website in new tab\n",
        "if __name__ == '__main__':\n",
        "    #app.run_server(mode='inline', debug=True)\n",
        "    app.run_server(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}