{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jvv9-YPh7peb"
      },
      "source": [
        "# Download YouTube Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zYL7qtzLC77u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7ebf238-0509-4c21-9216-2bd2fd60b35c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytube\n",
            "  Downloading pytube-12.1.2-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 KB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting youtube-dl\n",
            "  Downloading youtube_dl-2021.12.17-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spleeter\n",
            "  Downloading spleeter-2.3.2-py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.2/51.2 KB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow<3.0.0,>=2.5.0 in /usr/local/lib/python3.8/dist-packages (from spleeter) (2.9.2)\n",
            "Requirement already satisfied: protobuf<4.0.0,>=3.19.4 in /usr/local/lib/python3.8/dist-packages (from spleeter) (3.19.6)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.19.2 in /usr/local/lib/python3.8/dist-packages (from spleeter) (1.21.6)\n",
            "Collecting typer<0.4.0,>=0.3.2\n",
            "  Downloading typer-0.3.2-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: pandas<2.0,>=1.2 in /usr/local/lib/python3.8/dist-packages (from spleeter) (1.3.5)\n",
            "Requirement already satisfied: librosa<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from spleeter) (0.8.1)\n",
            "Collecting norbert==0.2.1\n",
            "  Downloading norbert-0.2.1-py2.py3-none-any.whl (11 kB)\n",
            "Collecting httpx[http2]<0.20.0,>=0.19.0\n",
            "  Downloading httpx-0.19.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.3/77.3 KB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llvmlite<0.39.0,>=0.38.0\n",
            "  Downloading llvmlite-0.38.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from ffmpeg-python==0.2.0->spleeter) (0.16.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from norbert==0.2.1->spleeter) (1.7.3)\n",
            "Collecting httpcore<0.14.0,>=0.13.3\n",
            "  Downloading httpcore-0.13.7-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 KB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986[idna2008]<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.8/dist-packages (from httpx[http2]<0.20.0,>=0.19.0->spleeter) (2.1.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from httpx[http2]<0.20.0,>=0.19.0->spleeter) (2022.12.7)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Collecting h2<5,>=3\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.8/dist-packages (from librosa<0.9.0,>=0.8.0->spleeter) (0.11.0)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.8/dist-packages (from librosa<0.9.0,>=0.8.0->spleeter) (0.56.4)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa<0.9.0,>=0.8.0->spleeter) (4.4.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa<0.9.0,>=0.8.0->spleeter) (1.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from librosa<0.9.0,>=0.8.0->spleeter) (23.0)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa<0.9.0,>=0.8.0->spleeter) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.8/dist-packages (from librosa<0.9.0,>=0.8.0->spleeter) (1.2.0)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.8/dist-packages (from librosa<0.9.0,>=0.8.0->spleeter) (1.6.0)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa<0.9.0,>=0.8.0->spleeter) (0.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas<2.0,>=1.2->spleeter) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas<2.0,>=1.2->spleeter) (2022.7.1)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (2.9.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (2.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (2.2.0)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (2.9.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (1.4.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (0.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (15.0.6.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (4.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (1.51.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (57.4.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (0.30.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (1.15.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (1.12)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (1.14.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<3.0.0,>=2.5.0->spleeter) (1.1.2)\n",
            "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.4.0,>=0.3.2->spleeter) (7.1.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow<3.0.0,>=2.5.0->spleeter) (0.38.4)\n",
            "Collecting hyperframe<7,>=6.0\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Collecting hpack<5,>=4.0\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Collecting anyio==3.*\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.13,>=0.11\n",
            "  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.9/54.9 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.8/dist-packages (from anyio==3.*->httpcore<0.14.0,>=0.13.3->httpx[http2]<0.20.0,>=0.19.0->spleeter) (2.10)\n",
            "Collecting numba>=0.43.0\n",
            "  Downloading numba-0.56.3-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m110.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading numba-0.56.2-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m115.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading numba-0.56.0-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m112.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading numba-0.55.2-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m112.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa<0.9.0,>=0.8.0->spleeter) (2.25.1)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.8/dist-packages (from pooch>=1.0->librosa<0.9.0,>=0.8.0->spleeter) (1.4.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa<0.9.0,>=0.8.0->spleeter) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.10.2->librosa<0.9.0,>=0.8.0->spleeter) (1.15.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.5.0->spleeter) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.5.0->spleeter) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.5.0->spleeter) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.5.0->spleeter) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.5.0->spleeter) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.5.0->spleeter) (2.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa<0.9.0,>=0.8.0->spleeter) (2.21)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.5.0->spleeter) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.5.0->spleeter) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.5.0->spleeter) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.5.0->spleeter) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.5.0->spleeter) (6.0.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa<0.9.0,>=0.8.0->spleeter) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa<0.9.0,>=0.8.0->spleeter) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.5.0->spleeter) (3.12.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.5.0->spleeter) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<3.0.0,>=2.5.0->spleeter) (3.2.2)\n",
            "Installing collected packages: youtube-dl, rfc3986, pydub, typer, sniffio, pytube, llvmlite, hyperframe, hpack, h11, ffmpeg-python, numba, norbert, h2, anyio, httpcore, httpx, spleeter\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.7.0\n",
            "    Uninstalling typer-0.7.0:\n",
            "      Successfully uninstalled typer-0.7.0\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.39.1\n",
            "    Uninstalling llvmlite-0.39.1:\n",
            "      Successfully uninstalled llvmlite-0.39.1\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.56.4\n",
            "    Uninstalling numba-0.56.4:\n",
            "      Successfully uninstalled numba-0.56.4\n",
            "Successfully installed anyio-3.6.2 ffmpeg-python-0.2.0 h11-0.12.0 h2-4.1.0 hpack-4.0.0 httpcore-0.13.7 httpx-0.19.0 hyperframe-6.0.1 llvmlite-0.38.1 norbert-0.2.1 numba-0.55.2 pydub-0.25.1 pytube-12.1.2 rfc3986-1.5.0 sniffio-1.3.0 spleeter-2.3.2 typer-0.3.2 youtube-dl-2021.12.17\n"
          ]
        }
      ],
      "source": [
        "!pip install pytube pydub youtube-dl spleeter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xPg1ZJXI_V-2"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import sys\n",
        "import shutil\n",
        "import torch\n",
        "import torchaudio\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from io import BytesIO\n",
        "\n",
        "from pydub import AudioSegment\n",
        "from pytube import YouTube"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "XMG11VA8CWKF"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_spleeter = True"
      ],
      "metadata": {
        "id": "in2Iobp_NjBk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FvJUpvVsYK7M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "4eeae67b1b2a494ca5890266c7152a18",
            "6cda17f5722d416ca9de9ca4e73d03f2",
            "44479bd7a54147e4afaa63e2d04f0f54",
            "550d5e9d8ac5413ebc9e50fe5009a011",
            "19014d66afc74a61b302cf1442f24a67",
            "1c7415bdd1b74dab850034731489001b",
            "9c91d481467e4470837f720312694b9b",
            "32fc646a787e46af99de5cd7198695cf",
            "df4425807c8d48f6b9cb3c0908ddd0c7",
            "085358ae5ad04da29a2ed9c0dfd77c10",
            "d1775fcfd1db4eeb87c31e558139bd24"
          ]
        },
        "outputId": "abe53abd-1938-4611-f024-46a7b3edc0d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/torchaudio/models/wav2vec2_fairseq_base_ls960_asr_ls960.pth\" to /root/.cache/torch/hub/checkpoints/wav2vec2_fairseq_base_ls960_asr_ls960.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/360M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4eeae67b1b2a494ca5890266c7152a18"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H\n",
        "labels = bundle.get_labels()\n",
        "model = bundle.get_model().to(device)\n",
        "dictionary = {c: i for i, c in enumerate(labels)}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if use_spleeter:\n",
        "  from spleeter.separator import Separator\n",
        "  # Initialize the separator\n",
        "  separator = Separator('spleeter:2stems')"
      ],
      "metadata": {
        "id": "uKRA6nb0NbqD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EuiWyfDDzI3h"
      },
      "outputs": [],
      "source": [
        "def get_wave(aud):\n",
        "  aud = aud.set_channels(1)\n",
        "  aud = aud.get_array_of_samples()\n",
        "  wave = torch.tensor(aud, dtype = torch.float)\n",
        "  wave = torch.reshape(wave, (1,wave.shape[0]))\n",
        "\n",
        "  return wave"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wav_sr_from_yt_video_id(video_id):\n",
        "    # Download the video using youtube-dl\n",
        "    os.system(\"youtube-dl --extract-audio --audio-format wav --audio-quality 0 -o '%(id)s.%(ext)s' https://youtu.be/{}\".format(video_id))\n",
        "\n",
        "    file_path = \"{}.wav\".format(video_id)\n",
        "    audio_path = file_path\n",
        "\n",
        "    if use_spleeter:\n",
        "      separator.separate_to_file(\"/content/{}.wav\".format(video_id), \"/content/\")\n",
        "      audio_path = \"/content/{}/vocals.wav\".format(video_id)\n",
        "\n",
        "    # Load the audio file using pydub\n",
        "    audio = AudioSegment.from_file(audio_path, format=\"wav\")\n",
        "\n",
        "    waveform = get_wave(audio)\n",
        "    sr = audio.frame_rate\n",
        "\n",
        "    # Delete file\n",
        "    if os.path.isfile(file_path):\n",
        "        os.remove(file_path)\n",
        "    else:\n",
        "        print(\"{} does not exist.\".format(file_path))\n",
        "\n",
        "    try:\n",
        "        shutil.rmtree(\"/content/{}\".format(video_id))\n",
        "    except OSError as e:\n",
        "        print(\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
        "        \n",
        "    # Resample\n",
        "    if sr != bundle.sample_rate:\n",
        "        waveform = torchaudio.functional.resample(waveform, sr, bundle.sample_rate)\n",
        "\n",
        "    return waveform, sr"
      ],
      "metadata": {
        "id": "M4OOyZbzKA7x"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "i6U_cJvYBkL4"
      },
      "outputs": [],
      "source": [
        "def clean_lyrics(lyrics):\n",
        "    lyrics = re.sub(r\"\\[.*?\\]\", \"\", lyrics, flags=re.MULTILINE)\n",
        "    lyrics = re.sub(r\"’\", \"'\", lyrics)\n",
        "    lyrics = re.sub(r\"[^a-zA-Z'’|-]|\\s\", \"|\", lyrics)\n",
        "    return lyrics.upper()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Ru8UVKPBHGhv"
      },
      "outputs": [],
      "source": [
        "def calculate_emission(waveform):\n",
        "    torch.cuda.empty_cache()    \n",
        "    \n",
        "    length = waveform.shape[1]\n",
        "    chunks = []\n",
        "    amount_chunks = 10\n",
        "    chunks_length = length//amount_chunks\n",
        "    for i in range(amount_chunks):\n",
        "        with torch.inference_mode():\n",
        "            emissions, _ = model(waveform[:, i * chunks_length: min(length, (i + 1) * chunks_length)].to(device))\n",
        "            emissions = torch.log_softmax(emissions, dim=-1)\n",
        "            chunks.append(emissions)\n",
        "\n",
        "    return torch.cat(chunks, dim=1)[0].cpu().detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9iv9CYtlFOSA"
      },
      "outputs": [],
      "source": [
        "def get_tokens(transcript):\n",
        "    return [dictionary[c] for c in transcript]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Rznzh7LnnHri"
      },
      "outputs": [],
      "source": [
        "def get_trellis(emission, tokens, blank_id=0):\n",
        "    num_frame = emission.size(0)\n",
        "    num_tokens = len(tokens)\n",
        "\n",
        "    # Trellis has extra diemsions for both time axis and tokens.\n",
        "    # The extra dim for tokens represents <SoS> (start-of-sentence)\n",
        "    # The extra dim for time axis is for simplification of the code.\n",
        "    trellis = torch.empty((num_frame + 1, num_tokens + 1))\n",
        "    trellis[0, 0] = 0\n",
        "    trellis[1:, 0] = torch.cumsum(emission[:, 0], 0)\n",
        "    trellis[0, -num_tokens:] = -float(\"inf\")\n",
        "    trellis[-num_tokens:, 0] = float(\"inf\")\n",
        "\n",
        "    for t in range(num_frame):\n",
        "        trellis[t + 1, 1:] = torch.maximum(\n",
        "            # Score for staying at the same token\n",
        "            trellis[t, 1:] + emission[t, blank_id],\n",
        "            # Score for changing to the next token\n",
        "            trellis[t, :-1] + emission[t, tokens],\n",
        "        )\n",
        "    return trellis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Y3Mf-_qnHrk"
      },
      "source": [
        "## Find the most likely path (backtracking)\n",
        "\n",
        "Once the trellis is generated, we will traverse it following the\n",
        "elements with high probability.\n",
        "\n",
        "We will start from the last label index with the time step of highest\n",
        "probability, then, we traverse back in time, picking stay\n",
        "($c_j \\rightarrow c_j$) or transition\n",
        "($c_j \\rightarrow c_{j+1}$), based on the post-transition\n",
        "probability $k_{t, j} p(t+1, c_{j+1})$ or\n",
        "$k_{t, j+1} p(t+1, repeat)$.\n",
        "\n",
        "Transition is done once the label reaches the beginning.\n",
        "\n",
        "The trellis matrix is used for path-finding, but for the final\n",
        "probability of each segment, we take the frame-wise probability from\n",
        "emission matrix.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "6wMrjfxdnHrl"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Point:\n",
        "    token_index: int\n",
        "    time_index: int\n",
        "    score: float\n",
        "\n",
        "\n",
        "def backtrack(trellis, emission, tokens, blank_id=0):\n",
        "    # Note:\n",
        "    # j and t are indices for trellis, which has extra dimensions\n",
        "    # for time and tokens at the beginning.\n",
        "    # When referring to time frame index `T` in trellis,\n",
        "    # the corresponding index in emission is `T-1`.\n",
        "    # Similarly, when referring to token index `J` in trellis,\n",
        "    # the corresponding index in transcript is `J-1`.\n",
        "    j = trellis.size(1) - 1\n",
        "    t_start = torch.argmax(trellis[:, j]).item()\n",
        "\n",
        "    path = []\n",
        "    for t in range(t_start, 0, -1):\n",
        "        # 1. Figure out if the current position was stay or change\n",
        "        # Note (again):\n",
        "        # `emission[J-1]` is the emission at time frame `J` of trellis dimension.\n",
        "        # Score for token staying the same from time frame J-1 to T.\n",
        "        stayed = trellis[t - 1, j] + emission[t - 1, blank_id]\n",
        "        # Score for token changing from C-1 at T-1 to J at T.\n",
        "        changed = trellis[t - 1, j - 1] + emission[t - 1, tokens[j - 1]]\n",
        "\n",
        "        # 2. Store the path with frame-wise probability.\n",
        "        prob = emission[t - 1, tokens[j - 1] if changed > stayed else 0].exp().item()\n",
        "        # Return token index and time index in non-trellis coordinate.\n",
        "        path.append(Point(j - 1, t - 1, prob))\n",
        "\n",
        "        # 3. Update the token\n",
        "        if changed > stayed:\n",
        "            j -= 1\n",
        "            if j == 0:\n",
        "                break\n",
        "    else:\n",
        "        raise ValueError(\"Failed to align\")\n",
        "    return path[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dTmzO9WBnHrn"
      },
      "outputs": [],
      "source": [
        "# Merge the labels\n",
        "@dataclass\n",
        "class Segment:\n",
        "    label: str\n",
        "    start: int\n",
        "    end: int\n",
        "    score: float\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"{self.label}\\t({self.score:4.2f}): [{self.start}, {self.end})\"\n",
        "\n",
        "    @property\n",
        "    def length(self):\n",
        "        return self.end - self.start\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash((self.label, self.start, self.end, self.score))\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        if not isinstance(other, Segment):\n",
        "            return False\n",
        "        return (self.label, self.start, self.end, self.score) == (other.label, other.start, other.end, other.score)\n",
        "\n",
        "\n",
        "\n",
        "def merge_repeats(path, transcript):\n",
        "    i1, i2 = 0, 0\n",
        "    segments = []\n",
        "    while i1 < len(path):\n",
        "        while i2 < len(path) and path[i1].token_index == path[i2].token_index:\n",
        "            i2 += 1\n",
        "        score = sum(path[k].score for k in range(i1, i2)) / (i2 - i1)\n",
        "        segments.append(\n",
        "            Segment(\n",
        "                transcript[path[i1].token_index],\n",
        "                path[i1].time_index,\n",
        "                path[i2 - 1].time_index + 1,\n",
        "                score,\n",
        "            )\n",
        "        )\n",
        "        i1 = i2\n",
        "    return segments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0azSem7nHro"
      },
      "source": [
        "### Visualization\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIVsRn3rnHrq"
      },
      "source": [
        "Looks good. Now let’s merge the words. The Wav2Vec2 model uses ``'|'``\n",
        "as the word boundary, so we merge the segments before each occurance of\n",
        "``'|'``.\n",
        "\n",
        "Then, finally, we segment the original audio into segmented audio and\n",
        "listen to them to see if the segmentation is correct.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "3wMoDWl9nHrs"
      },
      "outputs": [],
      "source": [
        "# Merge words\n",
        "def merge_words(segments, ratio, sr, separator=\"|\"):\n",
        "    words = []\n",
        "    i1, i2 = 0, 0\n",
        "    while i1 < len(segments):\n",
        "        if i2 >= len(segments) or segments[i2].label == separator:\n",
        "            if i1 != i2:\n",
        "                segs = segments[i1:i2]\n",
        "                word = \"\".join([seg.label for seg in segs])\n",
        "                score = sum(seg.score * seg.length for seg in segs) / sum(seg.length for seg in segs)\n",
        "\n",
        "                x0 = int(ratio * segments[i1].start)\n",
        "                x1 = int(ratio * segments[i2 - 1].end)\n",
        "                start = x0 / sr\n",
        "                end = x1 / sr\n",
        "\n",
        "                words.append(Segment(word, start, end, score))\n",
        "            i1 = i2 + 1\n",
        "            i2 = i1\n",
        "        else:\n",
        "            i2 += 1\n",
        "    return words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Abt3GSLvnHrt"
      },
      "source": [
        "### Visualization\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "9E9g0hvynHrx"
      },
      "outputs": [],
      "source": [
        "# A trick to embed the resulting audio to the generated file.\n",
        "# `IPython.display.Audio` has to be the last call in a cell,\n",
        "# and there should be only one call par cell.\n",
        "def display_segment(waveform, i):\n",
        "    ratio = waveform.size(1) / (trellis.size(0) - 1)\n",
        "    word = word_segments[i]\n",
        "    x0 = int(ratio * word.start)\n",
        "    x1 = int(ratio * word.end)\n",
        "    print(f\"{word.label} ({word.score:.2f}): {x0 / bundle.sample_rate:.3f} - {x1 / bundle.sample_rate:.3f} sec\")\n",
        "    segment = waveform[:, x0:x1]\n",
        "    return IPython.display.Audio(segment.numpy(), rate=bundle.sample_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "99C0VJxLEzO0"
      },
      "outputs": [],
      "source": [
        "def execute(audio, transcript):\n",
        "    transcript = clean_lyrics(transcript)\n",
        "    emission = calculate_emission(audio)\n",
        "    tokens = get_tokens(transcript)\n",
        "    trellis = get_trellis(emission, tokens)\n",
        "    path = backtrack(trellis, emission, tokens)\n",
        "    segments = merge_repeats(path, transcript)\n",
        "\n",
        "    ratio = audio.size(1) / (trellis.size(0) - 1)\n",
        "\n",
        "    word_segments = merge_words(segments, ratio=ratio, sr = bundle.sample_rate)\n",
        "    return emission, tokens, trellis, path, segments, word_segments"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_with_id(video_id, transcript):\n",
        "    waveform, sr = get_wav_sr_from_yt_video_id(video_id)\n",
        "    return execute(waveform, transcript)"
      ],
      "metadata": {
        "id": "DgR_HR6C5CPY"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Genre Prediction"
      ],
      "metadata": {
        "id": "3XOHgZtck2AO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "embed_len = 50\n",
        "hidden_dim = 75\n",
        "n_layers=1\n",
        "num_class = 7\n",
        "\n",
        "class LSTMClassifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LSTMClassifier, self).__init__()\n",
        "        self.embedding_layer = nn.Embedding(num_embeddings=len(vocab), embedding_dim=embed_len)\n",
        "        self.lstm = nn.LSTM(input_size=embed_len, hidden_size=hidden_dim, num_layers=n_layers, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, num_class)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, X_batch):\n",
        "        embeddings = self.embedding_layer(X_batch)\n",
        "        hidden, carry = torch.randn(n_layers, len(X_batch), hidden_dim), torch.randn(n_layers, len(X_batch), hidden_dim)\n",
        "        output, (hidden, carry) = self.lstm(embeddings, (hidden.to(device), carry.to(device)))\n",
        "        output = self.dropout(output)\n",
        "        return self.linear(output[:,-1])"
      ],
      "metadata": {
        "id": "9CTXtlpqV4um"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.optim import Adam\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "vocab = torch.load('vocab.pth')\n",
        "lstm_classifier = LSTMClassifier().to(device)\n",
        "optimizer = Adam(lstm_classifier.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "\n",
        "checkpoint = torch.load(\"/content/final_model.pth\")\n",
        "lstm_classifier.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint['epoch']\n",
        "loss = checkpoint['loss']\n",
        "lstm_classifier.eval()\n",
        "\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "text_pipeline = lambda x: vocab(tokenizer(x))\n",
        "\n",
        "import regex as re\n",
        "def clean_lyrics_2(lyrics):\n",
        "    lyrics = re.sub(r\"[^A-Za-z0-9']+\", \" \", lyrics, flags=re.MULTILINE)\n",
        "    lyrics = re.sub(r\"(?<=[a-zA-Z0-9]) (?=['])|(?<=[']) (?=[a-zA-Z0-9])\", \"\", lyrics, flags=re.MULTILINE)\n",
        "    lyrics = re.sub('\\s+',' ',lyrics)\n",
        "    return lyrics.lower().lstrip()\n",
        "\n",
        "decode_labels = {0:\"Pop\",1:\"R&B\",2:\"Hip Hop\",3:\"Rock\",4:\"Indie\",5:\"Country\",6:\"Heavy Metal\"}"
      ],
      "metadata": {
        "id": "C2dxy-XcWEVt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_genre(lyrics):\n",
        "  pred = lstm_classifier(torch.tensor(text_pipeline(clean_lyrics_2(lyrics))).unsqueeze(0).to(device))\n",
        "  label = decode_labels[F.softmax(pred, dim=-1).argmax(dim=-1).item()]\n",
        "  return label"
      ],
      "metadata": {
        "id": "OkplshtIvFNM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5r98YHbkoCD"
      },
      "source": [
        "# Website"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Oczo-aQF1y5t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33a72ed9-13da-40d3-d583-42c84e9acc21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting jupyter-dash\n",
            "  Downloading jupyter_dash-0.4.2-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.8/dist-packages (from jupyter-dash) (5.3.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from jupyter-dash) (2.25.1)\n",
            "Collecting retrying\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.8/dist-packages (from jupyter-dash) (1.1.4)\n",
            "Collecting dash\n",
            "  Downloading dash-2.8.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nest-asyncio\n",
            "  Downloading nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from jupyter-dash) (7.9.0)\n",
            "Collecting ansi2html\n",
            "  Downloading ansi2html-1.8.0-py3-none-any.whl (16 kB)\n",
            "Collecting dash-core-components==2.0.0\n",
            "  Downloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from dash->jupyter-dash) (5.5.0)\n",
            "Collecting dash-html-components==2.0.0\n",
            "  Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
            "Collecting dash-table==5.0.0\n",
            "  Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.8/dist-packages (from flask->jupyter-dash) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.8/dist-packages (from flask->jupyter-dash) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.8/dist-packages (from flask->jupyter-dash) (2.11.3)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.8/dist-packages (from flask->jupyter-dash) (1.0.1)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter-dash) (6.0.4)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter-dash) (6.1.12)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.8/dist-packages (from ipykernel->jupyter-dash) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->jupyter-dash) (2.0.10)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython->jupyter-dash) (57.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->jupyter-dash) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->jupyter-dash) (0.2.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->jupyter-dash) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->jupyter-dash) (4.4.2)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->jupyter-dash) (2.6.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->jupyter-dash) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->jupyter-dash) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->jupyter-dash) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->jupyter-dash) (2022.12.7)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from retrying->jupyter-dash) (1.15.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->jupyter-dash) (0.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2<3.0,>=2.10.1->flask->jupyter-dash) (2.0.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly>=5.0.0->dash->jupyter-dash) (8.1.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->jupyter-dash) (0.2.6)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.8/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (23.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (2.8.2)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.8/dist-packages (from jupyter-client->ipykernel->jupyter-dash) (5.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->jupyter-dash) (0.7.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.8/dist-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->jupyter-dash) (2.6.2)\n",
            "Installing collected packages: dash-table, dash-html-components, dash-core-components, retrying, nest-asyncio, jedi, ansi2html, dash, jupyter-dash\n",
            "Successfully installed ansi2html-1.8.0 dash-2.8.1 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 jedi-0.18.2 jupyter-dash-0.4.2 nest-asyncio-1.5.6 retrying-1.3.4\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytube in /usr/local/lib/python3.8/dist-packages (12.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dash-player\n",
            "  Downloading dash_player-1.0.6-py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: dash>=1.6.1 in /usr/local/lib/python3.8/dist-packages (from dash-player) (2.8.1)\n",
            "Requirement already satisfied: dash-core-components==2.0.0 in /usr/local/lib/python3.8/dist-packages (from dash>=1.6.1->dash-player) (2.0.0)\n",
            "Requirement already satisfied: dash-table==5.0.0 in /usr/local/lib/python3.8/dist-packages (from dash>=1.6.1->dash-player) (5.0.0)\n",
            "Requirement already satisfied: Flask>=1.0.4 in /usr/local/lib/python3.8/dist-packages (from dash>=1.6.1->dash-player) (1.1.4)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.8/dist-packages (from dash>=1.6.1->dash-player) (5.5.0)\n",
            "Requirement already satisfied: dash-html-components==2.0.0 in /usr/local/lib/python3.8/dist-packages (from dash>=1.6.1->dash-player) (2.0.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.8/dist-packages (from Flask>=1.0.4->dash>=1.6.1->dash-player) (1.0.1)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.8/dist-packages (from Flask>=1.0.4->dash>=1.6.1->dash-player) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.8/dist-packages (from Flask>=1.0.4->dash>=1.6.1->dash-player) (7.1.2)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.8/dist-packages (from Flask>=1.0.4->dash>=1.6.1->dash-player) (1.1.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly>=5.0.0->dash>=1.6.1->dash-player) (8.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from plotly>=5.0.0->dash>=1.6.1->dash-player) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=1.0.4->dash>=1.6.1->dash-player) (2.0.1)\n",
            "Installing collected packages: dash-player\n",
            "Successfully installed dash-player-1.0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install jupyter-dash\n",
        "!pip install pytube\n",
        "!pip install dash-player"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_tAGLtJW22L-"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Lmqgvp2x21n-"
      },
      "outputs": [],
      "source": [
        "def extract_video_id(link):\n",
        "    regExp = re.compile(r'^.*(youtu.be\\/|v\\/|u\\/\\w\\/|embed\\/|watch\\?v=|&v=)([^#&?]*).*')\n",
        "    match_id = regExp.match(link)\n",
        "    if match_id:\n",
        "        video_id = match_id.group(2)\n",
        "        if len(video_id) == 11:\n",
        "            return video_id \n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ysjNSJab2DeU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "bbe5b907-f057-4522-be44-0551354cec55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-815d554c4392>:2: UserWarning: \n",
            "The dash_core_components package is deprecated. Please replace\n",
            "`import dash_core_components as dcc` with `from dash import dcc`\n",
            "  import dash_core_components as dcc\n",
            "<ipython-input-25-815d554c4392>:3: UserWarning: \n",
            "The dash_html_components package is deprecated. Please replace\n",
            "`import dash_html_components as html` with `from dash import html`\n",
            "  import dash_html_components as html\n"
          ]
        }
      ],
      "source": [
        "from jupyter_dash import JupyterDash\n",
        "import dash_core_components as dcc\n",
        "import dash_html_components as html\n",
        "from dash.dependencies import Input, Output, State\n",
        "import dash_player"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "xaNdYyaRzT7X"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "TCiI_-3o3Ag1"
      },
      "outputs": [],
      "source": [
        "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
        "app = JupyterDash(__name__, external_stylesheets=external_stylesheets)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "HAPZVSK6FfyX"
      },
      "outputs": [],
      "source": [
        "app.layout = html.Div([\n",
        "    html.H1(\"AI Karaoke\"),\n",
        "    # Yt link\n",
        "    html.Div([\n",
        "        dcc.Input(id=\"input_yt\", placeholder=\"Input Youtube Link\", style={'width': '600px', 'margin-right': '5px'}),\n",
        "        html.Button('Submit', id='btn_submit', n_clicks=0, style={'margin': '0px 5px'}),\n",
        "        html.Button('Reset', id='btn_reset', n_clicks=0, style={'margin': '0px 5px'}),\n",
        "        dcc.Loading(\n",
        "            id=\"loading-1\",\n",
        "            children=html.Div(id=\"loading-output\", style={'display': 'none'})\n",
        "        ),\n",
        "        html.Div(id=\"initial_message\", children=\"Enter a YouTube link and transcript and press submit to load video\", style={'display': 'block'}),\n",
        "        html.Div(id=\"invalid_link_div\", children=\"Invalid YouTube link\", style={'color': 'red', 'display': 'none'}),\n",
        "        html.Div(id=\"no_transcript_div\", children=\"Please enter a transcript\", style={'color': 'red', 'display': 'none'}),\n",
        "    ], style={'margin-bottom': '5px'}),\n",
        "\n",
        "    # video and transcript\n",
        "    html.Div([\n",
        "        dash_player.DashPlayer(id=\"player\", url=\"\", controls=True, width=\"70%\", height=\"80%\", style={'display': 'inline-block', 'margin-right': '10px'}),\n",
        "        # TODO change input as you need\n",
        "        dcc.Textarea(id='input_transcript', value=\"\", placeholder=\"Input transcript\", style={'width': '29%', 'height': '80%', 'display': 'inline-block'}),\n",
        "        html.Div(id='output_transcript', children=[\n",
        "            html.Div(id='pre_transcript', style={'display': 'inline'}), \n",
        "            html.Span(id='pre_highlight_word', style={'display': 'inline', 'background-color': '#ffffb3'}), \n",
        "            html.Span(id='highlight_word', style={'display': 'inline', 'background-color': 'orange'}), \n",
        "            html.Span(id='post_highlight_word', style={'display': 'inline', 'background-color': '#ffff99'}), \n",
        "            html.Div(id='post_transcript', style={'display': 'inline'})\n",
        "            ], style={'width': '29%', 'height': '80%', 'display': 'none', 'overflow-y': 'auto'})\n",
        "    ], style={'height': '100vh', 'width': '100%', 'display': 'flex'}),\n",
        "\n",
        "    html.Div([\n",
        "        html.Div(id=\"genre_div\", children=\"Predicted Genre:\", style={'display': 'inline-block', 'margin-right': '5px'}),\n",
        "        html.Div(id=\"genre_class\", children=\"\", style={'display': 'inline-block', 'font-weight': 'bold'}),\n",
        "    ]),\n",
        "\n",
        "    # current video timestamp, only for debugging\n",
        "    html.Div(id=\"div_current_time\", style={\"margin\": \"10px 0px\"}),\n",
        "    dcc.Interval(id='interval', interval=2, n_intervals=0),\n",
        "    dcc.Store(id='clientside-store-data')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "mbTNd7q-INrw"
      },
      "outputs": [],
      "source": [
        "submit_clicks = 0\n",
        "reset_clicks = 0\n",
        "\n",
        "@app.callback(\n",
        "    Output('genre_class', 'children'),\n",
        "    Input('btn_submit', 'n_clicks'),\n",
        "    State('input_transcript', 'value')\n",
        ")\n",
        "def display_genre(n_clicks, transcript):\n",
        "    return predict_genre(transcript)\n",
        "\n",
        "@app.callback(\n",
        "    [Output('player', 'url'),\n",
        "    Output('initial_message', 'style'),\n",
        "    Output('invalid_link_div', 'style'),\n",
        "    Output('no_transcript_div', 'style'),\n",
        "    Output('input_transcript', 'style'),\n",
        "    Output('output_transcript', 'style'),\n",
        "    Output('clientside-store-data', 'data'),\n",
        "    Output('input_yt', 'value'),\n",
        "    Output('input_transcript', 'value'),\n",
        "     Output(\"loading-output\", \"children\")],\n",
        "    [Input('btn_submit', 'n_clicks'),\n",
        "    Input('btn_reset', 'n_clicks')],\n",
        "    [State('input_yt', 'value'),\n",
        "    State('input_transcript', 'value')]\n",
        ")\n",
        "def embed_video(btn_submit_n_clicks, btn_reset_n_clicks, link, transcript):\n",
        "    global submit_clicks\n",
        "    global reset_clicks\n",
        "\n",
        "    initial_message_style = {'display': 'block'}\n",
        "    invalid_style = {'color': 'red', 'display': 'none'}\n",
        "    no_transcript = {'color': 'red', 'display': 'none'}\n",
        "\n",
        "    input_style = {'width': '29%', 'height': '80%', 'display': 'inline-block', 'overflow-y': 'auto', 'border-style': 'solid', 'border-width': '1px'}\n",
        "    output_style = {'width': '29%', 'height': '80%', 'display': 'none', 'overflow-y': 'auto', 'border-style': 'solid', 'border-width': '1px'}\n",
        "\n",
        "    dict_words = {}\n",
        "    url = \"\"\n",
        "    if btn_submit_n_clicks > submit_clicks:\n",
        "        submit_clicks += 1\n",
        "        # TODO maybe add loading bar\n",
        "        video_id = extract_video_id(link)\n",
        "        if not video_id or not transcript:\n",
        "            initial_message_style = {'display': 'none'}\n",
        "            if not video_id:\n",
        "                invalid_style = {'color': 'red', 'display': 'block'}\n",
        "            if not transcript:\n",
        "                no_transcript = {'color': 'red', 'display': 'block'}\n",
        "        else:\n",
        "            url = link\n",
        "            input_style, output_style = output_style, input_style\n",
        "            waveform, sr = get_wav_sr_from_yt_video_id(video_id)\n",
        "            _, _, trellis, _, _, word_segments = execute(waveform, transcript)\n",
        "            dict_words = pd.DataFrame([vars(f) for f in word_segments]).to_dict('records')\n",
        "    \n",
        "    if btn_reset_n_clicks > reset_clicks:\n",
        "        reset_clicks += 1\n",
        "        transcript = \"\"\n",
        "\n",
        "    return url, initial_message_style, invalid_style, no_transcript, input_style, output_style, dict_words, url, transcript, None\n",
        "\n",
        "app.clientside_callback(\n",
        "    \"\"\"\n",
        "    function highlightWords(n_intervals, current_time, input, data) {\n",
        "        let pre_transcript = \"\";\n",
        "        let pre_highlight_word = \"\";\n",
        "        let highlight_word = \"\";\n",
        "        let post_highlight_word = \"\";\n",
        "        let post_transcript = \"\";\n",
        "        var listLength = data.length;\n",
        "        for (var i = 0; i < listLength; i++) {\n",
        "            let word = data[i];\n",
        "            if (current_time != null) {\n",
        "                start = word['start'];\n",
        "                end = word['end'];\n",
        "                if (current_time <= start - 1){\n",
        "                    post_transcript += ' ' + word['label'];\n",
        "                }\n",
        "                if (current_time >= start - 1 && current_time <= start){\n",
        "                    post_highlight_word += ' ' + word['label'];\n",
        "                }\n",
        "                if (current_time >= start && current_time <= end){\n",
        "                    highlight_word += word['label'];\n",
        "                }\n",
        "                if (current_time >= end && current_time <= end + 1){\n",
        "                    pre_highlight_word += word['label'] + ' ';\n",
        "                }\n",
        "                if (current_time >= end +1){\n",
        "                    pre_transcript += word['label'] + ' ';\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "        return [pre_transcript, pre_highlight_word, highlight_word, post_highlight_word, post_transcript];\n",
        "    }\n",
        "    \"\"\",\n",
        "    [Output('pre_transcript', 'children'),\n",
        "    Output('pre_highlight_word', 'children'),\n",
        "    Output('highlight_word', 'children'),\n",
        "    Output('post_highlight_word', 'children'),\n",
        "    Output('post_transcript', 'children')],\n",
        "    [Input('interval', 'n_intervals')],\n",
        "    [State('player', 'currentTime'),\n",
        "     State('input_transcript', 'value'),\n",
        "     State('clientside-store-data', 'data')]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "iTqlZniJ3IJx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "outputId": "98969261-a03f-40fe-b429-5b2a5ea818da"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(8050, \"/\", \"100%\", 650, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# click link to open website in new tab\n",
        "if __name__ == '__main__':\n",
        "    app.run_server(mode='inline')\n",
        "    # app.run_server(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4eeae67b1b2a494ca5890266c7152a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6cda17f5722d416ca9de9ca4e73d03f2",
              "IPY_MODEL_44479bd7a54147e4afaa63e2d04f0f54",
              "IPY_MODEL_550d5e9d8ac5413ebc9e50fe5009a011"
            ],
            "layout": "IPY_MODEL_19014d66afc74a61b302cf1442f24a67"
          }
        },
        "6cda17f5722d416ca9de9ca4e73d03f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c7415bdd1b74dab850034731489001b",
            "placeholder": "​",
            "style": "IPY_MODEL_9c91d481467e4470837f720312694b9b",
            "value": "100%"
          }
        },
        "44479bd7a54147e4afaa63e2d04f0f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32fc646a787e46af99de5cd7198695cf",
            "max": 377664473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df4425807c8d48f6b9cb3c0908ddd0c7",
            "value": 377664473
          }
        },
        "550d5e9d8ac5413ebc9e50fe5009a011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_085358ae5ad04da29a2ed9c0dfd77c10",
            "placeholder": "​",
            "style": "IPY_MODEL_d1775fcfd1db4eeb87c31e558139bd24",
            "value": " 360M/360M [00:01&lt;00:00, 275MB/s]"
          }
        },
        "19014d66afc74a61b302cf1442f24a67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c7415bdd1b74dab850034731489001b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c91d481467e4470837f720312694b9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32fc646a787e46af99de5cd7198695cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df4425807c8d48f6b9cb3c0908ddd0c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "085358ae5ad04da29a2ed9c0dfd77c10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1775fcfd1db4eeb87c31e558139bd24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}