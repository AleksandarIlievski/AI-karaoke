{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhkvDlMlf8F6"
      },
      "outputs": [],
      "source": [
        "!pip install pytube pydub youtube-dl spleeter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-2Yh86AC0Y-"
      },
      "source": [
        "## Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aXYcmHCE4Sq"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import sys\n",
        "import shutil\n",
        "import torch\n",
        "import torchaudio\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from io import BytesIO\n",
        "\n",
        "import plotly.express as px\n",
        "\n",
        "from pydub import AudioSegment\n",
        "from pytube import YouTube\n",
        "import librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9OLHyWXgWJV"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2vj76MsgY0y"
      },
      "outputs": [],
      "source": [
        "use_spleeter = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiLINA5hgh8M"
      },
      "outputs": [],
      "source": [
        "bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H\n",
        "labels = bundle.get_labels()\n",
        "model = bundle.get_model().to(device)\n",
        "dictionary = {c: i for i, c in enumerate(labels)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8QaMG_cgjCn"
      },
      "outputs": [],
      "source": [
        "if use_spleeter:\n",
        "  from spleeter.separator import Separator\n",
        "  # Initialize the separator\n",
        "  separator = Separator('spleeter:2stems')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEVDb1iPgn9v"
      },
      "outputs": [],
      "source": [
        "def get_wave(aud):\n",
        "  aud = aud.set_channels(1)\n",
        "  aud = aud.get_array_of_samples()\n",
        "  wave = torch.tensor(aud, dtype = torch.float)\n",
        "  wave = torch.reshape(wave, (1,wave.shape[0]))\n",
        "\n",
        "  return wave"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_p-A5hWkqz1N"
      },
      "outputs": [],
      "source": [
        "def get_wav_sr(file_dir, filename):\n",
        "\n",
        "    file_path =  os.path.join(file_dir, filename)\n",
        "    audio_path =  file_path\n",
        "    filename = filename.split('.mp3')[0]\n",
        "\n",
        "    if use_spleeter:\n",
        "      separator.separate_to_file(file_path, \"/content/\")\n",
        "      audio_path = f\"/content/{filename}/vocals.wav\"\n",
        "\n",
        "    # Load the audio file using pydub\n",
        "    if use_spleeter:\n",
        "      audio = AudioSegment.from_file(audio_path, format=\"wav\")\n",
        "    else:\n",
        "      audio = AudioSegment.from_file(audio_path, format=\"mp3\")\n",
        "\n",
        "    waveform = get_wave(audio)\n",
        "    sr = audio.frame_rate\n",
        "\n",
        "    # Delete file\n",
        "    if use_spleeter:\n",
        "      if os.path.isfile(audio_path):\n",
        "          os.remove(audio_path)\n",
        "      else:\n",
        "          print(\"{} does not exist.\".format(file_path))\n",
        "\n",
        "      try:\n",
        "          shutil.rmtree(f\"/content/{filename}\")\n",
        "      except OSError as e:\n",
        "          print(\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
        "        \n",
        "    # Resample\n",
        "    if sr != bundle.sample_rate:\n",
        "        waveform = torchaudio.functional.resample(waveform, sr, bundle.sample_rate)\n",
        "\n",
        "    return waveform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jv596h-Dgydj"
      },
      "outputs": [],
      "source": [
        "def clean_lyrics(lyrics):\n",
        "    lyrics = re.sub(r\"\\[\\t.*\\n?\\]\", \"\", lyrics, flags=re.MULTILINE)\n",
        "    lyrics = re.sub(r\"â€™\", \"\", lyrics)\n",
        "    lyrics = re.sub(r\"'\", \"\", lyrics)\n",
        "    lyrics = re.sub(r\"\\\\xa0\", \"\", lyrics)\n",
        "    lyrics = re.sub(r\"\\s\\s+\" , \" \", lyrics)\n",
        "    lyrics = re.sub(r\"[^a-zA-Z|-]|\\s\", \"|\", lyrics)\n",
        "    lyrics = re.sub(r\"\\|\\|+\" , \"|\", lyrics)\n",
        "    if lyrics[-1] == \"|\":\n",
        "      lyrics = lyrics[:-1]\n",
        "    return lyrics.upper()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MLIkCLq0gzhz"
      },
      "outputs": [],
      "source": [
        "def calculate_emission(waveform):\n",
        "    torch.cuda.empty_cache()    \n",
        "    \n",
        "    length = waveform.shape[1]\n",
        "    chunks = []\n",
        "    amount_chunks = 10\n",
        "    chunks_length = length//amount_chunks\n",
        "    for i in range(amount_chunks):\n",
        "        with torch.inference_mode():\n",
        "            emissions, _ = model(waveform[:, i * chunks_length: min(length, (i + 1) * chunks_length)].to(device))\n",
        "            emissions = torch.log_softmax(emissions, dim=-1)\n",
        "            chunks.append(emissions)\n",
        "\n",
        "    return torch.cat(chunks, dim=1)[0].cpu().detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VD34tuqAg2zS"
      },
      "outputs": [],
      "source": [
        "def get_tokens(transcript):\n",
        "    return [dictionary[c] for c in transcript]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjS5-xVbg2r8"
      },
      "outputs": [],
      "source": [
        "def get_trellis(emission, tokens, blank_id=0):\n",
        "    num_frame = emission.size(0)\n",
        "    num_tokens = len(tokens)\n",
        "\n",
        "    # Trellis has extra diemsions for both time axis and tokens.\n",
        "    # The extra dim for tokens represents <SoS> (start-of-sentence)\n",
        "    # The extra dim for time axis is for simplification of the code.\n",
        "    trellis = torch.empty((num_frame + 1, num_tokens + 1))\n",
        "    trellis[0, 0] = 0\n",
        "    trellis[1:, 0] = torch.cumsum(emission[:, 0], 0)\n",
        "    trellis[0, -num_tokens:] = -float(\"inf\")\n",
        "    trellis[-num_tokens:, 0] = float(\"inf\")\n",
        "\n",
        "    for t in range(num_frame):\n",
        "        trellis[t + 1, 1:] = torch.maximum(\n",
        "            # Score for staying at the same token\n",
        "            trellis[t, 1:] + emission[t, blank_id],\n",
        "            # Score for changing to the next token\n",
        "            trellis[t, :-1] + emission[t, tokens],\n",
        "        )\n",
        "    return trellis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTG3NJeOg-wF"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Point:\n",
        "    token_index: int\n",
        "    time_index: int\n",
        "    score: float\n",
        "\n",
        "\n",
        "def backtrack(trellis, emission, tokens, blank_id=0):\n",
        "    # Note:\n",
        "    # j and t are indices for trellis, which has extra dimensions\n",
        "    # for time and tokens at the beginning.\n",
        "    # When referring to time frame index `T` in trellis,\n",
        "    # the corresponding index in emission is `T-1`.\n",
        "    # Similarly, when referring to token index `J` in trellis,\n",
        "    # the corresponding index in transcript is `J-1`.\n",
        "    j = trellis.size(1) - 1\n",
        "    t_start = torch.argmax(trellis[:, j]).item()\n",
        "\n",
        "    path = []\n",
        "    for t in range(t_start, 0, -1):\n",
        "        # 1. Figure out if the current position was stay or change\n",
        "        # Note (again):\n",
        "        # `emission[J-1]` is the emission at time frame `J` of trellis dimension.\n",
        "        # Score for token staying the same from time frame J-1 to T.\n",
        "        stayed = trellis[t - 1, j] + emission[t - 1, blank_id]\n",
        "        # Score for token changing from C-1 at T-1 to J at T.\n",
        "        changed = trellis[t - 1, j - 1] + emission[t - 1, tokens[j - 1]]\n",
        "\n",
        "        # 2. Store the path with frame-wise probability.\n",
        "        prob = emission[t - 1, tokens[j - 1] if changed > stayed else 0].exp().item()\n",
        "        # Return token index and time index in non-trellis coordinate.\n",
        "        path.append(Point(j - 1, t - 1, prob))\n",
        "\n",
        "        # 3. Update the token\n",
        "        if changed > stayed:\n",
        "            j -= 1\n",
        "            if j == 0:\n",
        "                break\n",
        "    else:\n",
        "        raise ValueError(\"Failed to align\")\n",
        "    return path[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfQiMEOzhG8z"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Merge the labels\n",
        "@dataclass\n",
        "class Segment:\n",
        "    label: str\n",
        "    start: int\n",
        "    end: int\n",
        "    score: float\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"{self.label}\\t({self.score:4.2f}): [{self.start}, {self.end})\"\n",
        "\n",
        "    @property\n",
        "    def length(self):\n",
        "        return self.end - self.start\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash((self.label, self.start, self.end, self.score))\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        if not isinstance(other, Segment):\n",
        "            return False\n",
        "        return (self.label, self.start, self.end, self.score) == (other.label, other.start, other.end, other.score)\n",
        "\n",
        "\n",
        "\n",
        "def merge_repeats(path, transcript):\n",
        "    i1, i2 = 0, 0\n",
        "    segments = []\n",
        "    while i1 < len(path):\n",
        "        while i2 < len(path) and path[i1].token_index == path[i2].token_index:\n",
        "            i2 += 1\n",
        "        score = sum(path[k].score for k in range(i1, i2)) / (i2 - i1)\n",
        "        segments.append(\n",
        "            Segment(\n",
        "                transcript[path[i1].token_index],\n",
        "                path[i1].time_index,\n",
        "                path[i2 - 1].time_index + 1,\n",
        "                score,\n",
        "            )\n",
        "        )\n",
        "        i1 = i2\n",
        "    return segments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9RnGRwKEiAJc"
      },
      "outputs": [],
      "source": [
        "# Merge words\n",
        "def merge_words(segments, ratio, sr, separator=\"|\"):\n",
        "    words = []\n",
        "    i1, i2 = 0, 0\n",
        "    while i1 < len(segments):\n",
        "        if i2 >= len(segments) or segments[i2].label == separator:\n",
        "            if i1 != i2:\n",
        "                segs = segments[i1:i2]\n",
        "                word = \"\".join([seg.label for seg in segs])\n",
        "                score = sum(seg.score * seg.length for seg in segs) / sum(seg.length for seg in segs)\n",
        "\n",
        "                x0 = int(ratio * segments[i1].start)\n",
        "                x1 = int(ratio * segments[i2 - 1].end)\n",
        "                start = x0 / sr\n",
        "                end = x1 / sr\n",
        "\n",
        "                words.append(Segment(word, start, end, score))\n",
        "            i1 = i2 + 1\n",
        "            i2 = i1\n",
        "        else:\n",
        "            i2 += 1\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxpxQrEehG1R"
      },
      "outputs": [],
      "source": [
        "def execute(audio, transcript):\n",
        "    transcript = clean_lyrics(transcript)\n",
        "    emission = calculate_emission(audio)\n",
        "    tokens = get_tokens(transcript)\n",
        "    trellis = get_trellis(emission, tokens)\n",
        "    path = backtrack(trellis, emission, tokens)\n",
        "    segments = merge_repeats(path, transcript)\n",
        "\n",
        "    ratio = audio.size(1) / (trellis.size(0) - 1)\n",
        "\n",
        "    word_segments = merge_words(segments, ratio=ratio, sr = bundle.sample_rate)\n",
        "    return emission, tokens, trellis, path, segments, word_segments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6JtZ7DeI0Mm"
      },
      "outputs": [],
      "source": [
        "def get_timestamps(word_segments):\n",
        "    word_beginnings = []\n",
        "    word_endings = []\n",
        "    for i in range(len(word_segments)):\n",
        "      word_beginnings.append(word_segments[i]['start'])\n",
        "      if i < len(word_segments) - 1:\n",
        "        word_endings.append(word_segments[i+1]['start'])\n",
        "      else: \n",
        "        #word_endings.append(word_segments[i]['start'] + 1.0)\n",
        "        word_endings.append(word_segments[i]['end'])\n",
        "    return word_beginnings, word_endings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVMAxms3AEiG"
      },
      "source": [
        "# Load Testdataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9Pzpu_EILrI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poI7i5AX3_yE"
      },
      "outputs": [],
      "source": [
        "#### TODO upload the dataset on your drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-o3Jn_HF5xxZ"
      },
      "outputs": [],
      "source": [
        "def get_dataset(dir, sr=16000):\n",
        "  dir_waveforms = os.path.join(dir, 'mp3')\n",
        "  dir_y = os.path.join(dir, 'annotations/words')\n",
        "  dir_transcripts = os.path.join(dir, 'lyrics_raw')\n",
        "  dir_words =  os.path.join(dir, 'lyrics')\n",
        "\n",
        "  X = []\n",
        "  y_wb = []\n",
        "  y_we = []\n",
        "  transcripts = []\n",
        "  word_lengths = []\n",
        "\n",
        "  files = os.listdir(dir_waveforms)\n",
        "  files = sorted(files)\n",
        "  for filename in files:\n",
        "    # waveform\n",
        "    print(f\"Process {filename}\")\n",
        "    waveform = get_wav_sr(dir_waveforms, filename)\n",
        "    X.append(waveform)\n",
        "\n",
        "\n",
        "  files = os.listdir(dir_transcripts)\n",
        "  files = sorted(files)\n",
        "  for filename in files:\n",
        "    # lyrics\n",
        "    path_transcript = os.path.join(dir_transcripts, filename)\n",
        "    with open(path_transcript) as f:\n",
        "      transcript = f.read()\n",
        "    transcripts.append(transcript)\n",
        "    print(repr(transcript))\n",
        "\n",
        "  files = os.listdir(dir_words)\n",
        "  files = sorted(files)\n",
        "  for filename in files:\n",
        "    # words\n",
        "    path_words = os.path.join(dir_words, filename)\n",
        "    with open(path_words) as f:\n",
        "      words = f.readlines()\n",
        "    word_l = list(map(lambda x: len(x), words))\n",
        "    word_lengths.append(word_l)\n",
        "\n",
        "  assert len(word_lengths) == len(transcripts)\n",
        "\n",
        "\n",
        "  files = os.listdir(dir_y)\n",
        "  files = sorted(files)\n",
        "  #i = 0\n",
        "  for filename in files:\n",
        "    # label (list of timestamps for every word)\n",
        "    path_y = os.path.join(dir_y, filename)\n",
        "    df = pd.read_csv(path_y)\n",
        "    timestamps = df['word_start'].to_list()     \n",
        "    y_wb.append(timestamps)\n",
        "    timestamps = timestamps[1:] + [timestamps[-1] + 0.5]\n",
        "    y_we.append(timestamps)\n",
        "    #we = []\n",
        "    #for j in range(len(timestamps)):\n",
        "      \n",
        "    #  if  j < len(timestamps) - 1:\n",
        "    #    we.append(min(timestamps[j+1], timestamps[j] + word_lengths[i][j] * 0.1))\n",
        "\n",
        "    #    assert we[j] > timestamps[j]\n",
        "    #  else:\n",
        "    #    we.append(timestamps[j] + word_lengths[i][j] * 0.1)\n",
        "    #y_we.append(we)\n",
        "    #i += 1\n",
        "\n",
        "\n",
        "  return X, y_wb, y_we, transcripts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQiuZKgM9IQb"
      },
      "outputs": [],
      "source": [
        "sr = bundle.sample_rate\n",
        "# X = list of waveform (pytorch tensor)\n",
        "# y = list of list of timestamps of word beginnings\n",
        "#### TODO define the path to the testset\n",
        "X, y_wb, y_we, transcripts = get_dataset(\"/content/drive/MyDrive/hsr/testset\", sr=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-o7PqO-YpOBp"
      },
      "outputs": [],
      "source": [
        "print(repr(transcripts[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-ISgmhwmySr"
      },
      "outputs": [],
      "source": [
        "print(clean_lyrics(transcripts[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kh3CNfc5m3T8"
      },
      "outputs": [],
      "source": [
        "print(transcripts[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aR3FWLsKL2Qj"
      },
      "outputs": [],
      "source": [
        "IPython.display.Audio(X[1], rate=sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eixBK2ix39kr"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0AM6umM9y5H"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAu90b21UmIo"
      },
      "outputs": [],
      "source": [
        "def evaluate_average_absolute_error(y_pred, y_true, tolerance=0.3):\n",
        "  assert len(y_true) == len(y_pred)\n",
        "  deviations = np.abs(np.array(y_true) - np.array(y_pred))\n",
        "  return np.mean(deviations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SD5v-z3zPMdC"
      },
      "outputs": [],
      "source": [
        "def evaluate_accuracy(y_pred, y_true, tolerance=0.3):\n",
        "  #assert len(y_true) == len(y_pred)\n",
        "  deviations = np.abs(np.array(y_true) - np.array(y_pred))\n",
        "  return np.mean(deviations < tolerance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "16pRWpFljJj0"
      },
      "outputs": [],
      "source": [
        "def evaluate_iou(y_pred_wb, y_pred_we, y_true_wb, y_true_we):\n",
        "    ious = []\n",
        "\n",
        "    for i in range(len(y_pred_wb)):\n",
        "      if y_pred_wb[i] < y_true_wb[i]:\n",
        "        a1 = y_pred_wb[i]\n",
        "        a2 = y_pred_we[i]\n",
        "        b1 = y_true_wb[i]\n",
        "        b2 = y_true_we[i]\n",
        "      else:\n",
        "        a1 = y_true_wb[i]\n",
        "        a2 = y_true_we[i]\n",
        "        b1 = y_pred_wb[i]\n",
        "        b2 = y_pred_we[i] \n",
        "\n",
        "\n",
        "      assert (a1 < a2) & (b1 < b2)\n",
        "\n",
        "      # intersection\n",
        "      if a2 < b1:\n",
        "        intersection = 0\n",
        "      else:\n",
        "        lower = max(a1, b1)\n",
        "        upper = min(a2, b2)\n",
        "        intersection = upper - lower\n",
        "\n",
        "      # union\n",
        "      if a2 < b1:\n",
        "        union = a2 - a1 + b2 - b1\n",
        "      else:\n",
        "        lower = min(a1, b1)\n",
        "        upper = max(a2, b2)\n",
        "        union = upper - lower\n",
        "\n",
        "      iou = intersection / union\n",
        "      ious.append(iou)\n",
        "\n",
        "      assert iou >= 0.0\n",
        "\n",
        "    return np.mean(ious)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0RfEITkNQ2Il"
      },
      "outputs": [],
      "source": [
        "def evaluate(waveforms, y_true_wb, y_true_we, transcripts, sr=16000):\n",
        "  #assert len(y_true) == len(waveforms)\n",
        "  aaes = []\n",
        "  accs = []\n",
        "  ious = []\n",
        "\n",
        "  for i in range(len(waveforms)):\n",
        "    print(f\"Process audio {i}\")\n",
        "    _, _, trellis, _, _, word_segments = execute(waveforms[i], transcripts[i])\n",
        "    dict_words = pd.DataFrame([vars(f) for f in word_segments]).to_dict('records')\n",
        "\n",
        "    y_pred_wb,  y_pred_we = get_timestamps(dict_words)\n",
        "\n",
        "\n",
        "    if len(y_true_wb[i]) != len(y_pred_wb):\n",
        "      print('Skipping because of formating mismatch')\n",
        "      continue\n",
        "    \n",
        "\n",
        "    # Average Absoulute Error\n",
        "    aae = evaluate_average_absolute_error(y_pred_wb, y_true_wb[i])\n",
        "    aaes.append(aae)\n",
        "\n",
        "    # Accuracy\n",
        "    acc = evaluate_accuracy(y_pred_wb, y_true_wb[i])\n",
        "    accs.append(acc)\n",
        "\n",
        "    # Intersection over union\n",
        "    iou = evaluate_iou(y_pred_wb, y_pred_we, y_true_wb[i], y_true_we[i])\n",
        "    ious.append(iou)\n",
        "\n",
        "\n",
        "    print(f\"AAE of audio {i}: {aae}\")\n",
        "    print(f\"Accuracy of audio {i}: {acc}\")\n",
        "    print(f\"IOU of audio {i}: {iou}\")\n",
        "\n",
        "  print(f\"AAE: {np.mean(aaes)}\")\n",
        "  print(f\"Accuracy: {np.mean(accs)}\")\n",
        "  print(f\"IOU: {np.mean(ious)}\")\n",
        "\n",
        "  return aaes, accs, ious"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "39LjipkgSzGj"
      },
      "outputs": [],
      "source": [
        "aaes, accs, ious = evaluate(X, y_wb, y_we, transcripts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KZ1KUdYMR2kG"
      },
      "outputs": [],
      "source": [
        "fig = px.scatter(x=aaes, y=np.arange(0, len(aaes)))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "figX90UYSYJI"
      },
      "outputs": [],
      "source": [
        "fig = px.scatter(x=accs, y=np.arange(0, len(accs)))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zwtEe5U4-DvL"
      },
      "outputs": [],
      "source": [
        "fig = px.scatter(x=ious, y=np.arange(0, len(ious)))\n",
        "fig.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}