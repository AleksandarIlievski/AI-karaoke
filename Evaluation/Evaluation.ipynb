{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Same procedure as before"
      ],
      "metadata": {
        "id": "tNv3Ln0Blbp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kHBF0yswGfDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYL7qtzLC77u"
      },
      "outputs": [],
      "source": [
        "!pip install pydub youtube-dl spleeter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPg1ZJXI_V-2"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import sys\n",
        "import shutil\n",
        "import torch\n",
        "import torchaudio\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from io import BytesIO\n",
        "\n",
        "from pydub import AudioSegment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMG11VA8CWKF"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "use_spleeter = True"
      ],
      "metadata": {
        "id": "in2Iobp_NjBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvJUpvVsYK7M"
      },
      "outputs": [],
      "source": [
        "bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H\n",
        "labels = bundle.get_labels()\n",
        "model = bundle.get_model().to(device)\n",
        "dictionary = {c: i for i, c in enumerate(labels)}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if use_spleeter:\n",
        "  from spleeter.separator import Separator\n",
        "  # Initialize the separator\n",
        "  separator = Separator('spleeter:2stems')"
      ],
      "metadata": {
        "id": "uKRA6nb0NbqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuiWyfDDzI3h"
      },
      "outputs": [],
      "source": [
        "def get_wave(aud):\n",
        "  aud = aud.set_channels(1)\n",
        "  aud = aud.get_array_of_samples()\n",
        "  wave = torch.tensor(aud, dtype = torch.float)\n",
        "  wave = torch.reshape(wave, (1,wave.shape[0]))\n",
        "\n",
        "  return wave"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wav_sr_from_yt_video_id(video_id):\n",
        "    # Download the video using youtube-dl\n",
        "    os.system(\"youtube-dl --extract-audio --audio-format wav --audio-quality 0 -o '%(id)s.%(ext)s' https://youtu.be/{}\".format(video_id))\n",
        "\n",
        "    file_path = \"{}.wav\".format(video_id)\n",
        "    audio_path = file_path\n",
        "\n",
        "    if use_spleeter:\n",
        "      separator.separate_to_file(\"/content/{}.wav\".format(video_id), \"/content/\")\n",
        "      audio_path = \"/content/{}/vocals.wav\".format(video_id)\n",
        "\n",
        "    # Load the audio file using pydub\n",
        "    audio = AudioSegment.from_file(audio_path, format=\"wav\")\n",
        "\n",
        "    waveform = get_wave(audio)\n",
        "    sr = audio.frame_rate\n",
        "\n",
        "    # Delete file\n",
        "    if os.path.isfile(file_path):\n",
        "        os.remove(file_path)\n",
        "    else:\n",
        "        print(\"{} does not exist.\".format(file_path))\n",
        "\n",
        "    try:\n",
        "        shutil.rmtree(\"/content/{}\".format(video_id))\n",
        "    except OSError as e:\n",
        "        print(\"Error: %s - %s.\" % (e.filename, e.strerror))\n",
        "        \n",
        "    # Resample\n",
        "    if sr != bundle.sample_rate:\n",
        "        waveform = torchaudio.functional.resample(waveform, sr, bundle.sample_rate)\n",
        "\n",
        "    return waveform, sr"
      ],
      "metadata": {
        "id": "M4OOyZbzKA7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6U_cJvYBkL4"
      },
      "outputs": [],
      "source": [
        "def clean_lyrics(lyrics):\n",
        "    lyrics = re.sub(r\"\\[.*?\\]\", \"\", lyrics, flags=re.MULTILINE)\n",
        "    lyrics = re.sub(r\"’\", \"'\", lyrics)\n",
        "    lyrics = re.sub(r\"[^a-zA-Z'’|-]|\\s\", \"|\", lyrics)\n",
        "    return lyrics.upper()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ru8UVKPBHGhv"
      },
      "outputs": [],
      "source": [
        "def calculate_emission(waveform):\n",
        "    torch.cuda.empty_cache()    \n",
        "    \n",
        "    length = waveform.shape[1]\n",
        "    chunks = []\n",
        "    amount_chunks = 10\n",
        "    chunks_length = length//amount_chunks\n",
        "    for i in range(amount_chunks):\n",
        "        with torch.inference_mode():\n",
        "            emissions, _ = model(waveform[:, i * chunks_length: min(length, (i + 1) * chunks_length)].to(device))\n",
        "            emissions = torch.log_softmax(emissions, dim=-1)\n",
        "            chunks.append(emissions)\n",
        "\n",
        "    return torch.cat(chunks, dim=1)[0].cpu().detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iv9CYtlFOSA"
      },
      "outputs": [],
      "source": [
        "def get_tokens(transcript):\n",
        "    return [dictionary[c] for c in transcript]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rznzh7LnnHri"
      },
      "outputs": [],
      "source": [
        "def get_trellis(emission, tokens, blank_id=0):\n",
        "    num_frame = emission.size(0)\n",
        "    num_tokens = len(tokens)\n",
        "\n",
        "    # Trellis has extra diemsions for both time axis and tokens.\n",
        "    # The extra dim for tokens represents <SoS> (start-of-sentence)\n",
        "    # The extra dim for time axis is for simplification of the code.\n",
        "    trellis = torch.empty((num_frame + 1, num_tokens + 1))\n",
        "    trellis[0, 0] = 0\n",
        "    trellis[1:, 0] = torch.cumsum(emission[:, 0], 0)\n",
        "    trellis[0, -num_tokens:] = -float(\"inf\")\n",
        "    trellis[-num_tokens:, 0] = float(\"inf\")\n",
        "\n",
        "    for t in range(num_frame):\n",
        "        trellis[t + 1, 1:] = torch.maximum(\n",
        "            # Score for staying at the same token\n",
        "            trellis[t, 1:] + emission[t, blank_id],\n",
        "            # Score for changing to the next token\n",
        "            trellis[t, :-1] + emission[t, tokens],\n",
        "        )\n",
        "    return trellis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wMrjfxdnHrl"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Point:\n",
        "    token_index: int\n",
        "    time_index: int\n",
        "    score: float\n",
        "\n",
        "\n",
        "def backtrack(trellis, emission, tokens, blank_id=0):\n",
        "    # Note:\n",
        "    # j and t are indices for trellis, which has extra dimensions\n",
        "    # for time and tokens at the beginning.\n",
        "    # When referring to time frame index `T` in trellis,\n",
        "    # the corresponding index in emission is `T-1`.\n",
        "    # Similarly, when referring to token index `J` in trellis,\n",
        "    # the corresponding index in transcript is `J-1`.\n",
        "    j = trellis.size(1) - 1\n",
        "    t_start = torch.argmax(trellis[:, j]).item()\n",
        "\n",
        "    path = []\n",
        "    for t in range(t_start, 0, -1):\n",
        "        # 1. Figure out if the current position was stay or change\n",
        "        # Note (again):\n",
        "        # `emission[J-1]` is the emission at time frame `J` of trellis dimension.\n",
        "        # Score for token staying the same from time frame J-1 to T.\n",
        "        stayed = trellis[t - 1, j] + emission[t - 1, blank_id]\n",
        "        # Score for token changing from C-1 at T-1 to J at T.\n",
        "        changed = trellis[t - 1, j - 1] + emission[t - 1, tokens[j - 1]]\n",
        "\n",
        "        # 2. Store the path with frame-wise probability.\n",
        "        prob = emission[t - 1, tokens[j - 1] if changed > stayed else 0].exp().item()\n",
        "        # Return token index and time index in non-trellis coordinate.\n",
        "        path.append(Point(j - 1, t - 1, prob))\n",
        "\n",
        "        # 3. Update the token\n",
        "        if changed > stayed:\n",
        "            j -= 1\n",
        "            if j == 0:\n",
        "                break\n",
        "    else:\n",
        "        raise ValueError(\"Failed to align\")\n",
        "    return path[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTmzO9WBnHrn"
      },
      "outputs": [],
      "source": [
        "# Merge the labels\n",
        "@dataclass\n",
        "class Segment:\n",
        "    label: str\n",
        "    start: int\n",
        "    end: int\n",
        "    score: float\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"{self.label}\\t({self.score:4.2f}): [{self.start}, {self.end})\"\n",
        "\n",
        "    @property\n",
        "    def length(self):\n",
        "        return self.end - self.start\n",
        "\n",
        "    def __hash__(self):\n",
        "        return hash((self.label, self.start, self.end, self.score))\n",
        "\n",
        "    def __eq__(self, other):\n",
        "        if not isinstance(other, Segment):\n",
        "            return False\n",
        "        return (self.label, self.start, self.end, self.score) == (other.label, other.start, other.end, other.score)\n",
        "\n",
        "\n",
        "\n",
        "def merge_repeats(path, transcript):\n",
        "    i1, i2 = 0, 0\n",
        "    segments = []\n",
        "    while i1 < len(path):\n",
        "        while i2 < len(path) and path[i1].token_index == path[i2].token_index:\n",
        "            i2 += 1\n",
        "        score = sum(path[k].score for k in range(i1, i2)) / (i2 - i1)\n",
        "        segments.append(\n",
        "            Segment(\n",
        "                transcript[path[i1].token_index],\n",
        "                path[i1].time_index,\n",
        "                path[i2 - 1].time_index + 1,\n",
        "                score,\n",
        "            )\n",
        "        )\n",
        "        i1 = i2\n",
        "    return segments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wMoDWl9nHrs"
      },
      "outputs": [],
      "source": [
        "# Merge words\n",
        "def merge_words(segments, ratio, sr, separator=\"|\"):\n",
        "    words = []\n",
        "    i1, i2 = 0, 0\n",
        "    while i1 < len(segments):\n",
        "        if i2 >= len(segments) or segments[i2].label == separator:\n",
        "            if i1 != i2:\n",
        "                segs = segments[i1:i2]\n",
        "                word = \"\".join([seg.label for seg in segs])\n",
        "                score = sum(seg.score * seg.length for seg in segs) / sum(seg.length for seg in segs)\n",
        "\n",
        "                x0 = int(ratio * segments[i1].start)\n",
        "                x1 = int(ratio * segments[i2 - 1].end)\n",
        "                start = x0 / sr\n",
        "                end = x1 / sr\n",
        "\n",
        "                words.append(Segment(word, start, end, score))\n",
        "            i1 = i2 + 1\n",
        "            i2 = i1\n",
        "        else:\n",
        "            i2 += 1\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99C0VJxLEzO0"
      },
      "outputs": [],
      "source": [
        "def execute(audio, transcript):\n",
        "    transcript = clean_lyrics(transcript)\n",
        "    emission = calculate_emission(audio)\n",
        "    tokens = get_tokens(transcript)\n",
        "    trellis = get_trellis(emission, tokens)\n",
        "    path = backtrack(trellis, emission, tokens)\n",
        "    segments = merge_repeats(path, transcript)\n",
        "\n",
        "    ratio = audio.size(1) / (trellis.size(0) - 1)\n",
        "\n",
        "    word_segments = merge_words(segments, ratio=ratio, sr = bundle.sample_rate)\n",
        "    return emission, tokens, trellis, path, segments, word_segments"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def execute_with_id(video_id, transcript):\n",
        "    waveform, sr = get_wav_sr_from_yt_video_id(video_id)\n",
        "    return execute(waveform, transcript)"
      ],
      "metadata": {
        "id": "DgR_HR6C5CPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "RHphHC0ilrCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import math"
      ],
      "metadata": {
        "id": "1NeNISurjvFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_dir = \"/content/drive/MyDrive/ASR-Praktikum/4/eval\"\n",
        "use_spleeter = True"
      ],
      "metadata": {
        "id": "fjfuk92BGyFT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_hist = {}"
      ],
      "metadata": {
        "id": "Z5OaoGMVKWCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def IoU(truth, pred):\n",
        "    return intersect(truth, pred) / union(truth, pred)\n",
        "\n",
        "def intersect(truth, pred):\n",
        "    start_truth, end_truth = truth\n",
        "    start_pred, end_pred = pred\n",
        "\n",
        "    return max(0, min(end_truth, end_pred) - max(start_truth, start_pred))\n",
        "\n",
        "def union(truth, pred):\n",
        "    start_truth, end_truth = truth\n",
        "    start_pred, end_pred = pred\n",
        "    return max(end_truth, end_pred) - min(start_truth, start_pred)"
      ],
      "metadata": {
        "id": "Knaq1QKtF03k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def round_to_next_0_1(n):\n",
        "    return math.ceil(n * 10) / 10"
      ],
      "metadata": {
        "id": "jTJQbrK0MYfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "THRESHOLD = 0.2"
      ],
      "metadata": {
        "id": "GvJu6ajilDJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def calculate_IoU(csv_dir):\n",
        "    accum_iou_avg = 0\n",
        "    dict_id2iou = {}\n",
        "    df = pd.read_csv(os.path.join(csv_dir, 'eval_list.csv'))\n",
        "    df = df.reset_index() \n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        accum_iou = 0\n",
        "        small_words = 0\n",
        "        id = row['ID']\n",
        "        df_song = pd.read_csv(os.path.join(csv_dir, id + '.csv'))\n",
        "        df_song = df_song.reset_index()\n",
        "        _, _, _, _, _, word_segments = execute_with_id(id, row['Lyrics'])\n",
        "        for i, row_song in df_song.iterrows():\n",
        "            word = word_segments[i]\n",
        "            if word.end - word.start <= THRESHOLD:\n",
        "              small_words += 1\n",
        "            else:\n",
        "              truth = (float(row_song['start']), float(row_song['end']))\n",
        "              pred = (word.start, word.end)\n",
        "              iou = IoU(truth, pred)\n",
        "              accum_iou += iou\n",
        "\n",
        "              key = round_to_next_0_1(float(row_song['end']) - float(row_song['start']))\n",
        "              value = iou\n",
        "              dict_hist.setdefault(key, []).append(value)\n",
        "\n",
        "        avg = accum_iou / (len(df_song.index) - small_words)\n",
        "        dict_id2iou[id] = avg\n",
        "        accum_iou_avg += avg\n",
        "    avg_iou = accum_iou_avg / len(df.index)\n",
        "    return avg_iou, dict_id2iou"
      ],
      "metadata": {
        "id": "EGmeixcfMl5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_iou, dict_id2iou = calculate_IoU(csv_dir)"
      ],
      "metadata": {
        "id": "BWA6IuP7F4fE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_iou"
      ],
      "metadata": {
        "id": "MCYZTnMHiSzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_id2iou"
      ],
      "metadata": {
        "id": "R7Gxo0WTnz8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot each segment"
      ],
      "metadata": {
        "id": "Ptr7P6KIruXb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_dict = {key: sum(value) / len(value) for key, value in dict_hist.items()}\n",
        "\n",
        "#remove outlier for plotting\n",
        "mean_dict = {k: v for k, v in mean_dict.items() if k >= 0 and k < 3}\n",
        "\n",
        "keys = list(mean_dict.keys())\n",
        "values = list(mean_dict.values())\n",
        "\n",
        "sorted_keys = sorted(mean_dict.keys())\n",
        "sorted_values = [mean_dict[key] for key in sorted_keys]\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "for key, value in zip(sorted_keys, sorted_values):\n",
        "    ax.bar(key, value, width=0.05)\n",
        "\n",
        "for i, v in enumerate(sorted_values):\n",
        "    plt.annotate(len(dict_hist[sorted_keys[i]]), (sorted_keys[i], v), xytext=(0, 10), textcoords='offset points', ha='center', va='bottom')\n",
        "\n",
        "\n",
        "ax.set_xlabel('Length of Segment [s]')\n",
        "ax.set_ylabel('IoU')\n",
        "ax.set_title('')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LdQU8JkAN5US"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}